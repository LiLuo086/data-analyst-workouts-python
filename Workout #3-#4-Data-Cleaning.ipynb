{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ece497d7",
   "metadata": {},
   "source": [
    "### Table of Content\n",
    "- [Import Data](#Import-Data)\n",
    "- [Inspect Data](#Inspect-Data)\n",
    "- [Clean Data](#Clean-Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304dcb58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5bf8ff",
   "metadata": {},
   "source": [
    "### Import Data\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b99a1",
   "metadata": {},
   "source": [
    "In this workout, we use a dataset of [cafe sales](https://www.kaggle.com/datasets/ahmedmohamed2003/cafe-sales-dirty-data-for-cleaning-training) from kaggle to show how to use data cleaning techniques to process dirty data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6f318b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully. 10000 rows and 8 columns.\n"
     ]
    }
   ],
   "source": [
    "# Load the caf√© sales dataset\n",
    "data_path = Path(\"data/dirty_cafe_sales.csv\")\n",
    "\n",
    "# Check if the file exists\n",
    "if data_path.exists():\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\"Data loaded successfully. {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "else:\n",
    "    raise FileNotFoundError(f\"The file {data_path} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030bfe7",
   "metadata": {},
   "source": [
    "### Inspect Data\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aed85c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transaction ID</th>\n",
       "      <th>Item</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Price Per Unit</th>\n",
       "      <th>Total Spent</th>\n",
       "      <th>Payment Method</th>\n",
       "      <th>Location</th>\n",
       "      <th>Transaction Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_1961373</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>Takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_4977031</td>\n",
       "      <td>Cake</td>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Cash</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_4271903</td>\n",
       "      <td>Cookie</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>ERROR</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TXN_7034554</td>\n",
       "      <td>Salad</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TXN_3160411</td>\n",
       "      <td>Coffee</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Digital Wallet</td>\n",
       "      <td>In-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Transaction ID    Item Quantity Price Per Unit Total Spent  Payment Method  \\\n",
       "0    TXN_1961373  Coffee        2            2.0         4.0     Credit Card   \n",
       "1    TXN_4977031    Cake        4            3.0        12.0            Cash   \n",
       "2    TXN_4271903  Cookie        4            1.0       ERROR     Credit Card   \n",
       "3    TXN_7034554   Salad        2            5.0        10.0         UNKNOWN   \n",
       "4    TXN_3160411  Coffee        2            2.0         4.0  Digital Wallet   \n",
       "\n",
       "   Location Transaction Date  \n",
       "0  Takeaway       2023-09-08  \n",
       "1  In-store       2023-05-16  \n",
       "2  In-store       2023-07-19  \n",
       "3   UNKNOWN       2023-04-27  \n",
       "4  In-store       2023-06-11  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a first look\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa1b0c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 8 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Transaction ID    10000 non-null  object\n",
      " 1   Item              9667 non-null   object\n",
      " 2   Quantity          9862 non-null   object\n",
      " 3   Price Per Unit    9821 non-null   object\n",
      " 4   Total Spent       9827 non-null   object\n",
      " 5   Payment Method    7421 non-null   object\n",
      " 6   Location          6735 non-null   object\n",
      " 7   Transaction Date  9841 non-null   object\n",
      "dtypes: object(8)\n",
      "memory usage: 625.1+ KB\n",
      "\n",
      "Missing values in each column:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Transaction ID         0\n",
       "Item                 333\n",
       "Quantity             138\n",
       "Price Per Unit       179\n",
       "Total Spent          173\n",
       "Payment Method      2579\n",
       "Location            3265\n",
       "Transaction Date     159\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nDataFrame Information:\")\n",
    "df.info()\n",
    "\n",
    "print(\"\\nMissing values in each column:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311bdfd8",
   "metadata": {},
   "source": [
    "Through data inspecting we found that:\n",
    "- column names are not consistent: the names contain white space, lowercase and capital letters.\n",
    "- the data type of all columns are not correct, because of the messy data values, pandas cannot correctly recognize the data type.\n",
    "- some columns have wrong values, like `ERROR` and `UNKNOWN`\n",
    "- some columns have null values. \n",
    "\n",
    "So next we will dealing with these problems through data cleaning. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27da6f07",
   "metadata": {},
   "source": [
    "### Clean Data\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60951be5",
   "metadata": {},
   "source": [
    "#### Standardize column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f489f12b",
   "metadata": {},
   "source": [
    "In order to keep the consistency of column names between various tools and database, it's a good practice to remove the whitespace at the beginning and end of the column names, keep all names lowercase and replace the whitespace with underscore `_` in the column names. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee64f970",
   "metadata": {},
   "source": [
    "**Objectives**:\n",
    "- Remove spaces at beginning and end of column names\n",
    "- Lowercase column names \n",
    "- Replace white space between names with `_`\n",
    "\n",
    "\n",
    "**Methods**: `str.strip()`, `str.lower()`, `str.replace()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "95fc5583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Standardizing column names:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['transaction_id', 'item', 'quantity', 'price_per_unit', 'total_spent',\n",
       "       'payment_method', 'location', 'transaction_date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. Standardize column names ---\n",
    "# Standardize column names: strip whitespace, convert to lowercase, and replace spaces with underscores\n",
    "\n",
    "df.columns = (\n",
    "    df.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(' ', '_', regex=False)\n",
    ") \n",
    "\n",
    "print(\"\\nStandardizing column names:\")\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20a568b",
   "metadata": {},
   "source": [
    "#### Covert column types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae88d163",
   "metadata": {},
   "source": [
    "Through the first check of the data sample and the metadata of of the cafe sales dataset, we know that the data type of each column should be like:\n",
    "| Column           | Data Type category| \n",
    "|------------------|-------------------|\n",
    "| transaction_id   | text              | \n",
    "| item             | text              | \n",
    "| quantity         | number            | \n",
    "| price_per_unit   | number            |\n",
    "| total_spent      | number            |\n",
    "| payment_method   | text              |\n",
    "| location         | text              |\n",
    "| transaction_date | date              |\n",
    "\n",
    "So next step we convert the data type of each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8915b9b",
   "metadata": {},
   "source": [
    "### Convert numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df7d7f3",
   "metadata": {},
   "source": [
    "**Objectives**:\n",
    "- Remove commas and spaces in the data values\n",
    "- Convert data values to numbers \n",
    "- Replace invalid values with `NaN`.\n",
    "\n",
    "**Methods**: `replace()`, `pd.to_numeric()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79b25eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Convert numerical columns ---\n",
    "num_cols = ['quantity', 'price_per_unit', 'total_spent']\n",
    "df[num_cols] = (\n",
    "    df[num_cols]\n",
    "    .replace(r'[, \\s]', '', regex=True)  # Remove commas and spaces\n",
    "    .apply(pd.to_numeric, errors='coerce') # Convert to numeric, coercing errors to NaN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05930aea",
   "metadata": {},
   "source": [
    "### Convert date column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6a0ade",
   "metadata": {},
   "source": [
    "**Objectives**:\n",
    "- Convert transaction date strings into datetime objects.\n",
    "- Convert invalid formats to NaN.\n",
    "\n",
    "**Methods**: `replace()`, `pd.to_datetime()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b6e934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- 3. Convert date columns ---\n",
    "date_column = 'transaction_date'\n",
    "\n",
    "# Convert all non-string values to empty string, then replace invalid values with np.nan\n",
    "\n",
    "df[date_column] = df[date_column].map(lambda x: str(x).strip() if isinstance(x, str) else '')\n",
    "df[date_column] = df[date_column].replace({'': np.nan, 'unknown': np.nan, 'nan': np.nan}, regex=False)\n",
    "\n",
    "# Convert to datetime, let pandas infer the format, coerce errors to NaN\n",
    "df[date_column] = pd.to_datetime(df[date_column], errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7389e6",
   "metadata": {},
   "source": [
    "### Convert categorical string columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02e3724",
   "metadata": {},
   "source": [
    "**Objectives**:\n",
    "- Remove whitespace \n",
    "- Lowercase strings\n",
    "- Replace invalid strings with `NaN`\n",
    "\n",
    "**Methods**: `str.strip()`, `str.lower()`, `replace()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d35bfcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Convert text columns ---\n",
    "text_cols = ['transaction_id', 'item', 'payment_method', 'location']\n",
    "df[text_cols] = df[text_cols].apply(\n",
    "    lambda x: (x.str.strip()   # Strip whitespace\n",
    "               .str.lower()  # Convert to lowercase\n",
    "               .replace({'':np.nan, 'unknown':np.nan, 'nan':np.nan}, regex=False)) # Replace empty strings and 'unknown' with NaN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a63deb",
   "metadata": {},
   "source": [
    "### Check data types after conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e4ad7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data types of columns after conversion:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transaction_id              object\n",
       "item                        object\n",
       "quantity                   float64\n",
       "price_per_unit             float64\n",
       "total_spent                float64\n",
       "payment_method              object\n",
       "location                    object\n",
       "transaction_date    datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the data types of the numeric columns\n",
    "print(\"\\nData types of columns after conversion:\")\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7716f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>item</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price_per_unit</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>location</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>txn_1961373</td>\n",
       "      <td>coffee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>credit card</td>\n",
       "      <td>takeaway</td>\n",
       "      <td>2023-09-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>txn_4977031</td>\n",
       "      <td>cake</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>cash</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-05-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>txn_4271903</td>\n",
       "      <td>cookie</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>credit card</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-07-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>txn_7034554</td>\n",
       "      <td>salad</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-04-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>txn_3160411</td>\n",
       "      <td>coffee</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>digital wallet</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-06-11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  transaction_id    item  quantity  price_per_unit  total_spent  \\\n",
       "0    txn_1961373  coffee       2.0             2.0          4.0   \n",
       "1    txn_4977031    cake       4.0             3.0         12.0   \n",
       "2    txn_4271903  cookie       4.0             1.0          NaN   \n",
       "3    txn_7034554   salad       2.0             5.0         10.0   \n",
       "4    txn_3160411  coffee       2.0             2.0          4.0   \n",
       "\n",
       "   payment_method  location transaction_date  \n",
       "0     credit card  takeaway       2023-09-08  \n",
       "1            cash  in-store       2023-05-16  \n",
       "2     credit card  in-store       2023-07-19  \n",
       "3             NaN       NaN       2023-04-27  \n",
       "4  digital wallet  in-store       2023-06-11  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c1485",
   "metadata": {},
   "source": [
    "### Checking for Duplicates\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bebf17f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "#--- 5. Check for duplicate rows based on transaction_id ---\n",
    "print('Duplicate rows:', df.duplicated(subset=\"transaction_id\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7538109d",
   "metadata": {},
   "source": [
    "### Handling Missing Values\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f0e4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transaction_id         0\n",
       "item                 677\n",
       "quantity             479\n",
       "price_per_unit       533\n",
       "total_spent          502\n",
       "payment_method      2872\n",
       "location            3603\n",
       "transaction_date     460\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 6. checking for missing values ---\n",
    "print(\"\\nMissing values:\")\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a112fc",
   "metadata": {},
   "source": [
    "Since there are no extra information for the missing values in column `quantity`, `payment_method`, `location` and `transaction_date`, so the rows with missing values in these columns should be removed. The missing values in `price_per_unit` can be filled according to  the price of other existing items. `total_spent` can be calculated by `quantity * price_per_unit`. The missing `item` can be derived by its unique price. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40d90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Remove rows with missing values in critical columns ---\n",
    "drop_cols = ['quantity', 'payment_method', 'location', 'transaction_date']\n",
    "df = df.dropna(subset=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e66644f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4186, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ccd36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 8. fill missing price_per_unit based on item ---\n",
    "# create a price mapping dictionary from existing items\n",
    "price_list = {\n",
    "    'coffee': 2.0,\n",
    "    'tea': 1.5,\n",
    "    'sandwich': 4.0,\n",
    "    'salad': 5.0,\n",
    "    'cake': 3.0,\n",
    "    'cookie': 1.0,\n",
    "    'smoothie': 4.0,\n",
    "    'juice': 3.0\n",
    "}\n",
    "\n",
    "df['price_per_unit'] = df['price_per_unit'].fillna(df['item'].map(price_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4d49ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 9. fill missing price_per_unit based on item ---\n",
    "# create a reverse price mapping dictionary using unique prices\n",
    "reverse_price_list = {\n",
    "    2.0:'coffee',\n",
    "    1.5:'tea',    \n",
    "    5.0:'salad',   \n",
    "    1.0:'cookie'    \n",
    "}\n",
    "df['item'] = df['item'].fillna(df['price_per_unit'].map(reverse_price_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71a9d40d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>item</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price_per_unit</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>payment_method</th>\n",
       "      <th>location</th>\n",
       "      <th>transaction_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9136</th>\n",
       "      <td>txn_3587916</td>\n",
       "      <td>salad</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>cash</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-07-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8781</th>\n",
       "      <td>txn_4267136</td>\n",
       "      <td>tea</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>credit card</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-08-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>txn_3723007</td>\n",
       "      <td>tea</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>digital wallet</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8566</th>\n",
       "      <td>txn_1245485</td>\n",
       "      <td>cake</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>digital wallet</td>\n",
       "      <td>error</td>\n",
       "      <td>2023-05-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6292</th>\n",
       "      <td>txn_6884558</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cash</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-08-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>txn_5931292</td>\n",
       "      <td>error</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>credit card</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-12-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7242</th>\n",
       "      <td>txn_9970964</td>\n",
       "      <td>smoothie</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>credit card</td>\n",
       "      <td>takeaway</td>\n",
       "      <td>2023-07-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5007</th>\n",
       "      <td>txn_1015883</td>\n",
       "      <td>cookie</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>cash</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-10-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9584</th>\n",
       "      <td>txn_8955306</td>\n",
       "      <td>coffee</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>credit card</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-10-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>txn_3607652</td>\n",
       "      <td>salad</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>digital wallet</td>\n",
       "      <td>in-store</td>\n",
       "      <td>2023-06-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     transaction_id      item  quantity  price_per_unit  total_spent  \\\n",
       "9136    txn_3587916     salad       3.0             5.0         15.0   \n",
       "8781    txn_4267136       tea       1.0             1.5          1.5   \n",
       "303     txn_3723007       tea       3.0             1.5          4.5   \n",
       "8566    txn_1245485      cake       1.0             3.0          3.0   \n",
       "6292    txn_6884558       NaN       1.0             3.0          NaN   \n",
       "797     txn_5931292     error       2.0             4.0          8.0   \n",
       "7242    txn_9970964  smoothie       2.0             4.0          8.0   \n",
       "5007    txn_1015883    cookie       4.0             1.0          4.0   \n",
       "9584    txn_8955306    coffee       3.0             2.0          6.0   \n",
       "472     txn_3607652     salad       4.0             5.0         20.0   \n",
       "\n",
       "      payment_method  location transaction_date  \n",
       "9136            cash  in-store       2023-07-09  \n",
       "8781     credit card  in-store       2023-08-02  \n",
       "303   digital wallet  in-store       2023-05-18  \n",
       "8566  digital wallet     error       2023-05-15  \n",
       "6292            cash  in-store       2023-08-14  \n",
       "797      credit card  in-store       2023-12-18  \n",
       "7242     credit card  takeaway       2023-07-07  \n",
       "5007            cash  in-store       2023-10-16  \n",
       "9584     credit card  in-store       2023-10-14  \n",
       "472   digital wallet  in-store       2023-06-05  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6434fd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 10. Remove rows with missing values in item and price_per_unit columns ---\n",
    "drop_cols = ['item', 'price_per_unit']\n",
    "df = df.dropna(subset=drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8752fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 11. recalculate total_spent using cleaned quantity and price_per_unit ---\n",
    "df['total_spent'] = df['quantity'] * df['price_per_unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18b40d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "transaction_id      0\n",
       "item                0\n",
       "quantity            0\n",
       "price_per_unit      0\n",
       "total_spent         0\n",
       "payment_method      0\n",
       "location            0\n",
       "transaction_date    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\nMissing values:\")\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf3304b",
   "metadata": {},
   "source": [
    "### Final Checks\n",
    "----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6cab1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 12. check for negative values in price_per_unit and quantity ---\n",
    "\n",
    "# check for negative price_per_unit\n",
    "(df['price_per_unit']<0).sum()\n",
    "\n",
    "# check for negative quantities\n",
    "(df['quantity']<0).sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
